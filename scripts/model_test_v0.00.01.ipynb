{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from figen_class12 import FiGen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (2.0.11)\n",
      "Requirement already satisfied: numpy in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scipy in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->lightgbm) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->lightgbm) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): / WARNING conda.models.version:get_matcher(544): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.11.1\n",
      "  latest version: 23.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.9.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/jangsehwan/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - lightgbm\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openssl-1.1.1w             |       h8a1eda9_0         1.7 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.7 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl                                 1.1.1v-h8a1eda9_0 --> 1.1.1w-h8a1eda9_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge lightgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (2.6.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.7.3)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2022.1)\n",
      "Requirement already satisfied: six in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn.under_sampling\n",
    "!pip install imblearn.ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<임밸런스드 방법론>\n",
    "\n",
    "1. 언더샘플링\n",
    "2. 오버샘플링\n",
    "\n",
    "3. 언더샘플링+앙상블\n",
    "4. ctgan\n",
    "5. ctgan+앙상블\n",
    "6. FDDHS\n",
    "7. FDDHS+앙상블\n",
    "\n",
    "\n",
    "<인코딩 방법론>\n",
    "\n",
    "1. 범주형 변수 인코딩후 생성 -> 모델 적합후 성능 비교\n",
    "2. 범주형 변수 생성후 인코딩  -> 모델 적합후 성능 비교\n",
    "\n",
    "\n",
    "# 다음주 월요일 저녁 -> 본부장님, 상준님 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder, WOEEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class imblanced_compare:\n",
    "    \n",
    "    def __init__(self, data_path, categorical_columns:list):\n",
    "        self.data_path = data_path\n",
    "        self.categorical_columns = categorical_columns\n",
    "\n",
    "    def load_dataset(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        X = data.drop(columns=['target'])\n",
    "        y = data['target']\n",
    "        return X, y\n",
    "\n",
    "    def split_data(X, y, test_size=0.2, random_state=1004):\n",
    "        return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    def under_sampling(X_train, y_train):\n",
    "        rus = RandomUnderSampler()\n",
    "        X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "        return X_resampled, y_resampled\n",
    "    \n",
    "    def ensemble_under_sampling(X_train, y_train):\n",
    "        brf = BalancedRandomForestClassifier()\n",
    "        brf.fit(X_train, y_train)\n",
    "        return brf\n",
    "    \n",
    "    def generate_synthetic_data(self,X_resampled, y_resampled):\n",
    "        figen = FiGen(ratio=0.3, categorical_columns=self.categorical_columns)\n",
    "        synthetic_X, synthetic_y = figen.fit(X_resampled, y_resampled, X_train, y_train)\n",
    "        return synthetic_X, synthetic_y\n",
    "    \n",
    "    def encode_data(X_train, y_train):\n",
    "        ohe = OneHotEncoder()\n",
    "        X_ohe = ohe.fit_transform(X_train[categorical_columns])\n",
    "    \n",
    "        mean_encoder = TargetEncoder()\n",
    "        X_mean_encoded = mean_encoder.fit_transform(X_train[categorical_columns], y_train)\n",
    "    \n",
    "        woe_encoder = WOEEncoder()\n",
    "        X_woe_encoded = woe_encoder.fit_transform(X_train[categorical_columns], y_train)\n",
    "    \n",
    "        return X_ohe, X_mean_encoded, X_woe_encoded\n",
    "    \n",
    "    def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        return roc_auc, f1, classification_report(y_test, y_pred)\n",
    "    \n",
    "    def fit(self,data, categorical_columns:list):\n",
    "        # Load and preprocess data\n",
    "        X, y = self.load_dataset(data)\n",
    "        X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "        # Create LGBM model\n",
    "        lgbm_model = LGBMClassifier()\n",
    "    \n",
    "        # Under Sampling\n",
    "        X_resampled, y_resampled = self.under_sampling(X_train, y_train)\n",
    "        roc_auc_us, f1_us, report_us = self.evaluate_model(lgbm_model, X_resampled, y_resampled, X_test, y_test)\n",
    "    \n",
    "        # Ensemble with Under Sampling\n",
    "        brf = self.ensemble_under_sampling(X_train, y_train)\n",
    "        roc_auc_brf, f1_brf, report_brf = self.evaluate_model(brf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "        # Generate Synthetic Data\n",
    "        synthetic_X, synthetic_y = self.generate_synthetic_data(X_resampled, y_resampled)\n",
    "        roc_auc_syn, f1_syn, report_syn = self.evaluate_model(lgbm_model, synthetic_X, synthetic_y, X_test, y_test)\n",
    "    \n",
    "        # Encode Data\n",
    "        X_ohe, X_mean_encoded, X_woe_encoded = self.encode_data(X_train, y_train)\n",
    "        roc_auc_ohe, f1_ohe, report_ohe = self.evaluate_model(lgbm_model, X_ohe, y_train, X_test, y_test)\n",
    "        roc_auc_mean_encoded, f1_mean_encoded, report_mean_encoded = self.evaluate_model(lgbm_model, X_mean_encoded, y_train, X_test, y_test)\n",
    "        roc_auc_woe_encoded, f1_woe_encoded, report_woe_encoded = self.evaluate_model(lgbm_model, X_woe_encoded, y_train, X_test, y_test)\n",
    "    \n",
    "        # Print Results\n",
    "        print(\"Under Sampling Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_us)\n",
    "        print(\"F1 Score:\", f1_us)\n",
    "        print(report_us)\n",
    "    \n",
    "        print(\"\\nBalanced Random Forest Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_brf)\n",
    "        print(\"F1 Score:\", f1_brf)\n",
    "        print(report_brf)\n",
    "    \n",
    "        print(\"\\nSynthetic Data (FiGen) Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_syn)\n",
    "        print(\"F1 Score:\", f1_syn)\n",
    "        print(report_syn)\n",
    "    \n",
    "        print(\"\\nOne-Hot Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_ohe)\n",
    "        print(\"F1 Score:\", f1_ohe)\n",
    "        print(report_ohe)\n",
    "    \n",
    "        print(\"\\nMean Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_mean_encoded)\n",
    "        print(\"F1 Score:\", f1_mean_encoded)\n",
    "        print(report_mean_encoded)\n",
    "    \n",
    "        print(\"\\nWOE Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_woe_encoded)\n",
    "        print(\"F1 Score:\", f1_woe_encoded)\n",
    "        print(report_woe_encoded)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ImbalancedCompare(data_path='your_data.csv', categorical_columns=['cat_col1', 'cat_col2'])\n",
    "test.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder, WOEEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from figen_class12 import FiGen  # Assuming FiGen is imported from figen_class\n",
    "\n",
    "class ImbalancedCompare_lib:\n",
    "    \n",
    "    def __init__(self, categorical_columns: List[str], generation_rate: float):\n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.generation_rate = generation_rate\n",
    "\n",
    "\n",
    "    def split_data(self, X: pd.DataFrame, y: pd.Series, test_size: float = None, random_state: int = 1004) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "        \"\"\"\n",
    "        Split the dataset into train and test sets.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Feature matrix.\n",
    "            y (pd.Series): Target variable.\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            random_state (int): Seed for random number generator.\n",
    "\n",
    "        Returns:\n",
    "            X_train (pd.DataFrame): Training features.\n",
    "            X_test (pd.DataFrame): Testing features.\n",
    "            y_train (pd.Series): Training target.\n",
    "            y_test (pd.Series): Testing target.\n",
    "        \"\"\"\n",
    "        if test_size is None:\n",
    "            test_size = self.generation_rate\n",
    "        \n",
    "        return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    def under_sampling(self, X_train: pd.DataFrame, y_train: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Apply random under-sampling to balance the classes.\n",
    "\n",
    "        Args:\n",
    "            X_train (pd.DataFrame): Training features.\n",
    "            y_train (pd.Series): Training target.\n",
    "\n",
    "        Returns:\n",
    "            X_resampled (pd.DataFrame): Resampled features.\n",
    "            y_resampled (pd.Series): Resampled target.\n",
    "        \"\"\"\n",
    "        rus = RandomUnderSampler()\n",
    "        X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "        return X_resampled, y_resampled\n",
    "    \n",
    "    # ... (Other functions)\n",
    "\n",
    "    def generate_synthetic_data(self, X_resampled: pd.DataFrame, y_resampled: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Generate synthetic data using FiGen.\n",
    "\n",
    "        Args:\n",
    "            X_resampled (pd.DataFrame): Resampled features.\n",
    "            y_resampled (pd.Series): Resampled target.\n",
    "\n",
    "        Returns:\n",
    "            synthetic_X (pd.DataFrame): Synthetic features.\n",
    "            synthetic_y (pd.Series): Synthetic target.\n",
    "        \"\"\"\n",
    "        figen = FiGen(ratio=0.3, categorical_columns=self.categorical_columns)\n",
    "        synthetic_X, synthetic_y = figen.fit(X_resampled, y_resampled, X_train, y_train)\n",
    "        return synthetic_X, synthetic_y\n",
    "    \n",
    "        # 모델 평가 함수 (추가)\n",
    "    def evaluate_model(self, model, X_train, y_train, X_test, y_test):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        return roc_auc, f1, report\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        \"\"\"\n",
    "        Fit the model and evaluate various techniques.\n",
    "\n",
    "        Args:\n",
    "            data (str): Path to the dataset file.\n",
    "        \"\"\"\n",
    "        # Load and preprocess data\n",
    "        X_train, X_test, y_train, y_test = self.split_data(X, y)\n",
    "    \n",
    "        # Create LGBM model\n",
    "        lgbm_model = LGBMClassifier()\n",
    "    \n",
    "        # Under Sampling\n",
    "        X_resampled, y_resampled = self.under_sampling(X_train, y_train)\n",
    "        roc_auc_us, f1_us, report_us = self.evaluate_model(lgbm_model, X_resampled, y_resampled, X_test, y_test)\n",
    "    \n",
    "        # Ensemble with Under Sampling\n",
    "        brf = self.ensemble_under_sampling(X_train, y_train)\n",
    "        roc_auc_brf, f1_brf, report_brf = self.evaluate_model(brf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "        # Generate Synthetic Data\n",
    "        synthetic_X, synthetic_y = self.generate_synthetic_data(X_resampled, y_resampled)\n",
    "        roc_auc_syn, f1_syn, report_syn = self.evaluate_model(lgbm_model, synthetic_X, synthetic_y, X_test, y_test)\n",
    "    \n",
    "         # Encode Data\n",
    "        X_ohe, X_mean_encoded, X_woe_encoded = self.encode_data(X_train, y_train)\n",
    "        roc_auc_ohe, f1_ohe, report_ohe = self.evaluate_model(lgbm_model, X_ohe, y_train, X_test, y_test)\n",
    "        roc_auc_mean_encoded, f1_mean_encoded, report_mean_encoded = self.evaluate_model(lgbm_model, X_mean_encoded, y_train, X_test, y_test)\n",
    "        roc_auc_woe_encoded, f1_woe_encoded, report_woe_encoded = self.evaluate_model(lgbm_model, X_woe_encoded, y_train, X_test, y_test)\n",
    "    \n",
    "        # Print Results\n",
    "        print(\"Under Sampling Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_us)\n",
    "        print(\"F1 Score:\", f1_us)\n",
    "        print(report_us)\n",
    "    \n",
    "        print(\"\\nBalanced Random Forest Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_brf)\n",
    "        print(\"F1 Score:\", f1_brf)\n",
    "        print(report_brf)\n",
    "    \n",
    "        print(\"\\nSynthetic Data (FiGen) Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_syn)\n",
    "        print(\"F1 Score:\", f1_syn)\n",
    "        print(report_syn)\n",
    "    \n",
    "        print(\"\\nOne-Hot Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_ohe)\n",
    "        print(\"F1 Score:\", f1_ohe)\n",
    "        print(report_ohe)\n",
    "    \n",
    "        print(\"\\nMean Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_mean_encoded)\n",
    "        print(\"F1 Score:\", f1_mean_encoded)\n",
    "        print(report_mean_encoded)\n",
    "    \n",
    "        print(\"\\nWOE Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_woe_encoded)\n",
    "        print(\"F1 Score:\", f1_woe_encoded)\n",
    "        print(report_woe_encoded)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 144, 'name': 'Statlog (German Credit Data)', 'repository_url': 'https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data', 'data_url': 'https://archive.ics.uci.edu/static/public/144/data.csv', 'abstract': 'This dataset classifies people described by a set of attributes as good or bad credit risks. Comes in two formats (one all numeric). Also comes with a cost matrix', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1000, 'num_features': 20, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Other', 'Marital Status', 'Age', 'Occupation'], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1994, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5NC77', 'creators': ['Hans Hofmann'], 'intro_paper': None, 'additional_info': {'summary': 'Two datasets are provided.  the original dataset, in the form provided by Prof. Hofmann, contains categorical/symbolic attributes and is in the file \"german.data\".   \\r\\n \\r\\nFor algorithms that need numerical attributes, Strathclyde University produced the file \"german.data-numeric\".  This file has been edited and several indicator variables added to make it suitable for algorithms which cannot cope with categorical variables.   Several attributes that are ordered categorical (such as attribute 17) have been coded as integer.    This was the form used by StatLog.\\r\\n\\r\\nThis dataset requires use of a cost matrix (see below)\\r\\n\\r\\n ..... 1        2\\r\\n----------------------------\\r\\n  1   0        1\\r\\n-----------------------\\r\\n  2   5        0\\r\\n\\r\\n(1 = Good,  2 = Bad)\\r\\n\\r\\nThe rows represent the actual classification and the columns the predicted classification.\\r\\n\\r\\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Attribute 1:  (qualitative)      \\r\\n Status of existing checking account\\r\\n             A11 :      ... <    0 DM\\r\\n\\t       A12 : 0 <= ... <  200 DM\\r\\n\\t       A13 :      ... >= 200 DM / salary assignments for at least 1 year\\r\\n               A14 : no checking account\\r\\n\\r\\nAttribute 2:  (numerical)\\r\\n\\t      Duration in month\\r\\n\\r\\nAttribute 3:  (qualitative)\\r\\n\\t      Credit history\\r\\n\\t      A30 : no credits taken/ all credits paid back duly\\r\\n              A31 : all credits at this bank paid back duly\\r\\n\\t      A32 : existing credits paid back duly till now\\r\\n              A33 : delay in paying off in the past\\r\\n\\t      A34 : critical account/  other credits existing (not at this bank)\\r\\n\\r\\nAttribute 4:  (qualitative)\\r\\n\\t      Purpose\\r\\n\\t      A40 : car (new)\\r\\n\\t      A41 : car (used)\\r\\n\\t      A42 : furniture/equipment\\r\\n\\t      A43 : radio/television\\r\\n\\t      A44 : domestic appliances\\r\\n\\t      A45 : repairs\\r\\n\\t      A46 : education\\r\\n\\t      A47 : (vacation - does not exist?)\\r\\n\\t      A48 : retraining\\r\\n\\t      A49 : business\\r\\n\\t      A410 : others\\r\\n\\r\\nAttribute 5:  (numerical)\\r\\n\\t      Credit amount\\r\\n\\r\\nAttibute 6:  (qualitative)\\r\\n\\t      Savings account/bonds\\r\\n\\t      A61 :          ... <  100 DM\\r\\n\\t      A62 :   100 <= ... <  500 DM\\r\\n\\t      A63 :   500 <= ... < 1000 DM\\r\\n\\t      A64 :          .. >= 1000 DM\\r\\n              A65 :   unknown/ no savings account\\r\\n\\r\\nAttribute 7:  (qualitative)\\r\\n\\t      Present employment since\\r\\n\\t      A71 : unemployed\\r\\n\\t      A72 :       ... < 1 year\\r\\n\\t      A73 : 1  <= ... < 4 years  \\r\\n\\t      A74 : 4  <= ... < 7 years\\r\\n\\t      A75 :       .. >= 7 years\\r\\n\\r\\nAttribute 8:  (numerical)\\r\\n\\t      Installment rate in percentage of disposable income\\r\\n\\r\\nAttribute 9:  (qualitative)\\r\\n\\t      Personal status and sex\\r\\n\\t      A91 : male   : divorced/separated\\r\\n\\t      A92 : female : divorced/separated/married\\r\\n              A93 : male   : single\\r\\n\\t      A94 : male   : married/widowed\\r\\n\\t      A95 : female : single\\r\\n\\r\\nAttribute 10: (qualitative)\\r\\n\\t      Other debtors / guarantors\\r\\n\\t      A101 : none\\r\\n\\t      A102 : co-applicant\\r\\n\\t      A103 : guarantor\\r\\n\\r\\nAttribute 11: (numerical)\\r\\n\\t      Present residence since\\r\\n\\r\\nAttribute 12: (qualitative)\\r\\n\\t      Property\\r\\n\\t      A121 : real estate\\r\\n\\t      A122 : if not A121 : building society savings agreement/ life insurance\\r\\n              A123 : if not A121/A122 : car or other, not in attribute 6\\r\\n\\t      A124 : unknown / no property\\r\\n\\r\\nAttribute 13: (numerical)\\r\\n\\t      Age in years\\r\\n\\r\\nAttribute 14: (qualitative)\\r\\n\\t      Other installment plans \\r\\n\\t      A141 : bank\\r\\n\\t      A142 : stores\\r\\n\\t      A143 : none\\r\\n\\r\\nAttribute 15: (qualitative)\\r\\n\\t      Housing\\r\\n\\t      A151 : rent\\r\\n\\t      A152 : own\\r\\n\\t      A153 : for free\\r\\n\\r\\nAttribute 16: (numerical)\\r\\n              Number of existing credits at this bank\\r\\n\\r\\nAttribute 17: (qualitative)\\r\\n\\t      Job\\r\\n\\t      A171 : unemployed/ unskilled  - non-resident\\r\\n\\t      A172 : unskilled - resident\\r\\n\\t      A173 : skilled employee / official\\r\\n\\t      A174 : management/ self-employed/\\r\\n\\t\\t     highly qualified employee/ officer\\r\\n\\r\\nAttribute 18: (numerical)\\r\\n\\t      Number of people being liable to provide maintenance for\\r\\n\\r\\nAttribute 19: (qualitative)\\r\\n\\t      Telephone\\r\\n\\t      A191 : none\\r\\n\\t      A192 : yes, registered under the customers name\\r\\n\\r\\nAttribute 20: (qualitative)\\r\\n\\t      foreign worker\\r\\n\\t      A201 : yes\\r\\n\\t      A202 : no\\r\\n', 'citation': None}}\n",
      "           name     role         type     demographic  \\\n",
      "0    Attribute1  Feature  Categorical            None   \n",
      "1    Attribute2  Feature      Integer            None   \n",
      "2    Attribute3  Feature  Categorical            None   \n",
      "3    Attribute4  Feature  Categorical            None   \n",
      "4    Attribute5  Feature      Integer            None   \n",
      "5    Attribute6  Feature  Categorical            None   \n",
      "6    Attribute7  Feature  Categorical           Other   \n",
      "7    Attribute8  Feature      Integer            None   \n",
      "8    Attribute9  Feature  Categorical  Marital Status   \n",
      "9   Attribute10  Feature  Categorical            None   \n",
      "10  Attribute11  Feature      Integer            None   \n",
      "11  Attribute12  Feature  Categorical            None   \n",
      "12  Attribute13  Feature      Integer             Age   \n",
      "13  Attribute14  Feature  Categorical            None   \n",
      "14  Attribute15  Feature  Categorical           Other   \n",
      "15  Attribute16  Feature      Integer            None   \n",
      "16  Attribute17  Feature  Categorical      Occupation   \n",
      "17  Attribute18  Feature      Integer            None   \n",
      "18  Attribute19  Feature       Binary            None   \n",
      "19  Attribute20  Feature       Binary           Other   \n",
      "20        class   Target       Binary            None   \n",
      "\n",
      "                                          description   units missing_values  \n",
      "0                 Status of existing checking account    None             no  \n",
      "1                                            Duration  months             no  \n",
      "2                                      Credit history    None             no  \n",
      "3                                             Purpose    None             no  \n",
      "4                                       Credit amount    None             no  \n",
      "5                               Savings account/bonds    None             no  \n",
      "6                            Present employment since    None             no  \n",
      "7   Installment rate in percentage of disposable i...    None             no  \n",
      "8                             Personal status and sex    None             no  \n",
      "9                          Other debtors / guarantors    None             no  \n",
      "10                            Present residence since    None             no  \n",
      "11                                           Property    None             no  \n",
      "12                                                Age   years             no  \n",
      "13                            Other installment plans    None             no  \n",
      "14                                            Housing    None             no  \n",
      "15            Number of existing credits at this bank    None             no  \n",
      "16                                                Job    None             no  \n",
      "17  Number of people being liable to provide maint...    None             no  \n",
      "18                                          Telephone    None             no  \n",
      "19                                     foreign worker    None             no  \n",
      "20                                  1 = Good, 2 = Bad    None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "statlog_german_credit_data = fetch_ucirepo(id=144) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_german_credit_data.data.features \n",
    "y = statlog_german_credit_data.data.targets \n",
    "\n",
    "# metadata \n",
    "print(statlog_german_credit_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(statlog_german_credit_data.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImbalancedCompare_lib' object has no attribute 'evaluate_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb 셀 11\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m comparator \u001b[39m=\u001b[39m ImbalancedCompare_lib( categorical_columns\u001b[39m=\u001b[39mcategorical_columns_list, generation_rate\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# 모델을 학습하고 다양한 기술을 평가합니다.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m comparator\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "\u001b[1;32m/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb 셀 11\u001b[0m in \u001b[0;36mImbalancedCompare_lib.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb#X16sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39m# Under Sampling\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb#X16sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m X_resampled, y_resampled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munder_sampling(X_train, y_train)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb#X16sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m roc_auc_us, f1_us, report_us \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_model(lgbm_model, X_resampled, y_resampled, X_test, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb#X16sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# Ensemble with Under Sampling\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/imbalanced-ddhs/scripts/model_test_v0.00.01.ipynb#X16sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m brf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensemble_under_sampling(X_train, y_train)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImbalancedCompare_lib' object has no attribute 'evaluate_model'"
     ]
    }
   ],
   "source": [
    "# 범주형 변수의 컬럼명을 저장할 빈 리스트 생성\n",
    "categorical_columns_list = []\n",
    "\n",
    "# 데이터프레임의 컬럼을 순회하면서 데이터 유형을 확인\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':  # 데이터 유형이 'object'인 경우 (범주형 변수)\n",
    "        categorical_columns_list.append(column) \n",
    "\n",
    "\n",
    "# 클래스의 인스턴스를 생성합니다.\n",
    "comparator = ImbalancedCompare_lib( categorical_columns=categorical_columns_list, generation_rate=0.3)\n",
    "\n",
    "# 모델을 학습하고 다양한 기술을 평가합니다.\n",
    "comparator.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDHS\n",
    "\n",
    "1. 데이터 다운 (완)\n",
    "2. 모델 피팅 파이프라인 수정\n",
    "3. Figen 에러 고치기\n",
    "4. 1회 돌려보기\n",
    "5. 해당 내용 커밋\n",
    "6. 10.25 결과 리뷰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
