{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import figen_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge lightgbm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn.under_sampling\n",
    "!pip install imblearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder, WOEEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "import figen_class \n",
    "\n",
    "\n",
    "\n",
    "class imblanced_compare:\n",
    "    \n",
    "    def __init__(self, data_path, categorical_columns:list):\n",
    "        self.data_path = data_path\n",
    "        self.categorical_columns = categorical_columns\n",
    "\n",
    "    def load_dataset(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        X = data.drop(columns=['target'])\n",
    "        y = data['target']\n",
    "        return X, y\n",
    "\n",
    "    def split_data(X, y, test_size=0.2, random_state=1004):\n",
    "        return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    def under_sampling(X_train, y_train):\n",
    "        rus = RandomUnderSampler()\n",
    "        X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "        return X_resampled, y_resampled\n",
    "    \n",
    "    def ensemble_under_sampling(X_train, y_train):\n",
    "        brf = BalancedRandomForestClassifier()\n",
    "        brf.fit(X_train, y_train)\n",
    "        return brf\n",
    "    \n",
    "    def generate_synthetic_data(self,X_resampled, y_resampled):\n",
    "        figen = FiGen(ratio=0.3, categorical_columns=self.categorical_columns)\n",
    "        synthetic_X, synthetic_y = figen.fit(X_resampled, y_resampled, X_train, y_train)\n",
    "        return synthetic_X, synthetic_y\n",
    "    \n",
    "    def encode_data(X_train, y_train):\n",
    "        ohe = OneHotEncoder()\n",
    "        X_ohe = ohe.fit_transform(X_train[categorical_columns])\n",
    "    \n",
    "        mean_encoder = TargetEncoder()\n",
    "        X_mean_encoded = mean_encoder.fit_transform(X_train[categorical_columns], y_train)\n",
    "    \n",
    "        woe_encoder = WOEEncoder()\n",
    "        X_woe_encoded = woe_encoder.fit_transform(X_train[categorical_columns], y_train)\n",
    "    \n",
    "        return X_ohe, X_mean_encoded, X_woe_encoded\n",
    "    \n",
    "    def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        return roc_auc, f1, classification_report(y_test, y_pred)\n",
    "    \n",
    "    def fit(self,data, categorical_columns:list):\n",
    "        # Load and preprocess data\n",
    "        X, y = self.load_dataset(data)\n",
    "        X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "        # Create LGBM model\n",
    "        lgbm_model = LGBMClassifier()\n",
    "    \n",
    "        # Under Sampling\n",
    "        X_resampled, y_resampled = self.under_sampling(X_train, y_train)\n",
    "        roc_auc_us, f1_us, report_us = self.evaluate_model(lgbm_model, X_resampled, y_resampled, X_test, y_test)\n",
    "    \n",
    "        # Ensemble with Under Sampling\n",
    "        brf = self.ensemble_under_sampling(X_train, y_train)\n",
    "        roc_auc_brf, f1_brf, report_brf = self.evaluate_model(brf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "        # Generate Synthetic Data\n",
    "        synthetic_X, synthetic_y = self.generate_synthetic_data(X_resampled, y_resampled)\n",
    "        roc_auc_syn, f1_syn, report_syn = self.evaluate_model(lgbm_model, synthetic_X, synthetic_y, X_test, y_test)\n",
    "    \n",
    "        # Encode Data\n",
    "        X_ohe, X_mean_encoded, X_woe_encoded = self.encode_data(X_train, y_train)\n",
    "        roc_auc_ohe, f1_ohe, report_ohe = self.evaluate_model(lgbm_model, X_ohe, y_train, X_test, y_test)\n",
    "        roc_auc_mean_encoded, f1_mean_encoded, report_mean_encoded = self.evaluate_model(lgbm_model, X_mean_encoded, y_train, X_test, y_test)\n",
    "        roc_auc_woe_encoded, f1_woe_encoded, report_woe_encoded = self.evaluate_model(lgbm_model, X_woe_encoded, y_train, X_test, y_test)\n",
    "    \n",
    "        # Print Results\n",
    "        print(\"Under Sampling Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_us)\n",
    "        print(\"F1 Score:\", f1_us)\n",
    "        print(report_us)\n",
    "    \n",
    "        print(\"\\nBalanced Random Forest Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_brf)\n",
    "        print(\"F1 Score:\", f1_brf)\n",
    "        print(report_brf)\n",
    "    \n",
    "        print(\"\\nSynthetic Data (FiGen) Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_syn)\n",
    "        print(\"F1 Score:\", f1_syn)\n",
    "        print(report_syn)\n",
    "    \n",
    "        print(\"\\nOne-Hot Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_ohe)\n",
    "        print(\"F1 Score:\", f1_ohe)\n",
    "        print(report_ohe)\n",
    "    \n",
    "        print(\"\\nMean Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_mean_encoded)\n",
    "        print(\"F1 Score:\", f1_mean_encoded)\n",
    "        print(report_mean_encoded)\n",
    "    \n",
    "        print(\"\\nWOE Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_woe_encoded)\n",
    "        print(\"F1 Score:\", f1_woe_encoded)\n",
    "        print(report_woe_encoded)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ImbalancedCompare(data_path='your_data.csv', categorical_columns=['cat_col1', 'cat_col2'])\n",
    "test.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder, WOEEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from figen_class import FiGen  # Assuming FiGen is imported from figen_class\n",
    "\n",
    "class ImbalancedCompare:\n",
    "    \n",
    "    def __init__(self, data_path: str, categorical_columns: List[str], generation_rate: float):\n",
    "        self.data_path = data_path\n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.generation_rate = generation_rate\n",
    "\n",
    "    def load_dataset(self, file_path: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Load and preprocess the dataset from the given file path.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the CSV dataset file.\n",
    "\n",
    "        Returns:\n",
    "            X (pd.DataFrame): Feature matrix.\n",
    "            y (pd.Series): Target variable.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(file_path)\n",
    "        X = data.drop(columns=['target'])\n",
    "        y = data['target']\n",
    "        return X, y\n",
    "\n",
    "    def split_data(self, X: pd.DataFrame, y: pd.Series, test_size: float = self.generation_rate, random_state: int = 1004) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "        \"\"\"\n",
    "        Split the dataset into train and test sets.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Feature matrix.\n",
    "            y (pd.Series): Target variable.\n",
    "            test_size (float): Proportion of the dataset to include in the test split.\n",
    "            random_state (int): Seed for random number generator.\n",
    "\n",
    "        Returns:\n",
    "            X_train (pd.DataFrame): Training features.\n",
    "            X_test (pd.DataFrame): Testing features.\n",
    "            y_train (pd.Series): Training target.\n",
    "            y_test (pd.Series): Testing target.\n",
    "        \"\"\"\n",
    "        return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    def under_sampling(self, X_train: pd.DataFrame, y_train: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Apply random under-sampling to balance the classes.\n",
    "\n",
    "        Args:\n",
    "            X_train (pd.DataFrame): Training features.\n",
    "            y_train (pd.Series): Training target.\n",
    "\n",
    "        Returns:\n",
    "            X_resampled (pd.DataFrame): Resampled features.\n",
    "            y_resampled (pd.Series): Resampled target.\n",
    "        \"\"\"\n",
    "        rus = RandomUnderSampler()\n",
    "        X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "        return X_resampled, y_resampled\n",
    "    \n",
    "    # ... (Other functions)\n",
    "\n",
    "    def generate_synthetic_data(self, X_resampled: pd.DataFrame, y_resampled: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Generate synthetic data using FiGen.\n",
    "\n",
    "        Args:\n",
    "            X_resampled (pd.DataFrame): Resampled features.\n",
    "            y_resampled (pd.Series): Resampled target.\n",
    "\n",
    "        Returns:\n",
    "            synthetic_X (pd.DataFrame): Synthetic features.\n",
    "            synthetic_y (pd.Series): Synthetic target.\n",
    "        \"\"\"\n",
    "        figen = FiGen(ratio=0.3, categorical_columns=self.categorical_columns)\n",
    "        synthetic_X, synthetic_y = figen.fit(X_resampled, y_resampled, X_train, y_train)\n",
    "        return synthetic_X, synthetic_y\n",
    "    \n",
    "    \n",
    "    def fit(self, data: str):\n",
    "        \"\"\"\n",
    "        Fit the model and evaluate various techniques.\n",
    "\n",
    "        Args:\n",
    "            data (str): Path to the dataset file.\n",
    "        \"\"\"\n",
    "        # Load and preprocess data\n",
    "        X, y = self.load_dataset(data)\n",
    "        X_train, X_test, y_train, y_test = self.split_data(X, y)\n",
    "    \n",
    "        # Create LGBM model\n",
    "        lgbm_model = LGBMClassifier()\n",
    "    \n",
    "        # Under Sampling\n",
    "        X_resampled, y_resampled = self.under_sampling(X_train, y_train)\n",
    "        roc_auc_us, f1_us, report_us = self.evaluate_model(lgbm_model, X_resampled, y_resampled, X_test, y_test)\n",
    "    \n",
    "        # Ensemble with Under Sampling\n",
    "        brf = self.ensemble_under_sampling(X_train, y_train)\n",
    "        roc_auc_brf, f1_brf, report_brf = self.evaluate_model(brf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "        # Generate Synthetic Data\n",
    "        synthetic_X, synthetic_y = self.generate_synthetic_data(X_resampled, y_resampled)\n",
    "        roc_auc_syn, f1_syn, report_syn = self.evaluate_model(lgbm_model, synthetic_X, synthetic_y, X_test, y_test)\n",
    "    \n",
    "         # Encode Data\n",
    "        X_ohe, X_mean_encoded, X_woe_encoded = self.encode_data(X_train, y_train)\n",
    "        roc_auc_ohe, f1_ohe, report_ohe = self.evaluate_model(lgbm_model, X_ohe, y_train, X_test, y_test)\n",
    "        roc_auc_mean_encoded, f1_mean_encoded, report_mean_encoded = self.evaluate_model(lgbm_model, X_mean_encoded, y_train, X_test, y_test)\n",
    "        roc_auc_woe_encoded, f1_woe_encoded, report_woe_encoded = self.evaluate_model(lgbm_model, X_woe_encoded, y_train, X_test, y_test)\n",
    "    \n",
    "        # Print Results\n",
    "        print(\"Under Sampling Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_us)\n",
    "        print(\"F1 Score:\", f1_us)\n",
    "        print(report_us)\n",
    "    \n",
    "        print(\"\\nBalanced Random Forest Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_brf)\n",
    "        print(\"F1 Score:\", f1_brf)\n",
    "        print(report_brf)\n",
    "    \n",
    "        print(\"\\nSynthetic Data (FiGen) Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_syn)\n",
    "        print(\"F1 Score:\", f1_syn)\n",
    "        print(report_syn)\n",
    "    \n",
    "        print(\"\\nOne-Hot Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_ohe)\n",
    "        print(\"F1 Score:\", f1_ohe)\n",
    "        print(report_ohe)\n",
    "    \n",
    "        print(\"\\nMean Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_mean_encoded)\n",
    "        print(\"F1 Score:\", f1_mean_encoded)\n",
    "        print(report_mean_encoded)\n",
    "    \n",
    "        print(\"\\nWOE Encoding Results:\")\n",
    "        print(\"ROC AUC:\", roc_auc_woe_encoded)\n",
    "        print(\"F1 Score:\", f1_woe_encoded)\n",
    "        print(report_woe_encoded)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
